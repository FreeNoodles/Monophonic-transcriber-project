{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "from librosa import display\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout, Dense\n",
    "from keras.losses import binary_crossentropy,categorical_crossentropy\n",
    "from keras.activations import sigmoid, relu\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import rmsprop, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "#try optimizer adam instead of rmsprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_directory_training= r'C:\\Users\\Gebruiker\\Desktop\\MonoPhonic\\data\\training\\images'\n",
    "path_labels_training= r'C:\\Users\\Gebruiker\\Desktop\\MonoPhonic\\data\\training\\labels.csv'\n",
    "\n",
    "path_labels_valid =  r'C:\\Users\\Gebruiker\\Desktop\\MonoPhonic\\data\\valid\\labels.csv'\n",
    "path_directory_valid =  r'C:\\Users\\Gebruiker\\Desktop\\MonoPhonic\\data\\valid\\images'\n",
    "\n",
    "path_directory_test = r'C:\\Users\\Gebruiker\\Desktop\\MonoPhonic\\data\\test\\images'\n",
    "path_labels_test =   r'C:\\Users\\Gebruiker\\Desktop\\MonoPhonic\\data\\test\\labels.csv'\n",
    "\n",
    "class_list = ['A0','A#0','B0','C1','C#1','D1','D#1','E1','F1',\n",
    "         'F#1','G1','G#1','A1','A#1','B1','C2','C#2','D2','D#2','E2','F2',\n",
    "         'F#2','G2','G#2','A2','A#2','B2','C3','C#3','D3','D#3','E3','F3',\n",
    "         'F#3','G3','G#3','A3','A#3','B3','C4','C#4','D4','D#4','E4','F4',\n",
    "         'F#4','G4','G#4','A4','A#4','B4','C5','C#5','D5','D#5','E5','F5',\n",
    "         'F#5','G5','G#5','A5','A#5','B5','C6','C#6','D6','D#6','E6','F6',\n",
    "         'F#6','G6','G#6','A6','A#6','B6','C7','C#7','D7','D#7','E7','F7',\n",
    "         'F#7','G7','G#7','A7','A#7','B7','C8']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 validated image filenames.\n",
      "Found 2080 validated image filenames.\n",
      "Found 651 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "df_training = pd.read_csv(path_labels_training)\n",
    "\n",
    "df_valid = pd.read_csv(path_labels_valid)\n",
    "\n",
    "df_test = pd.read_csv(path_labels_test)\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "df_training[0:32],\n",
    "directory=path_directory_training,\n",
    "x_col='filename',\n",
    "y_col=class_list,\n",
    "batch_size=32,\n",
    "target_size=(100,100),\n",
    "class_mode='raw',\n",
    "shuffle= False)\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "df_valid,\n",
    "directory=path_directory_valid,\n",
    "x_col='filename',\n",
    "y_col=class_list,\n",
    "batch_size=32,\n",
    "target_size=(100,100),\n",
    "class_mode='raw',\n",
    "shuffle= True,\n",
    "color_mode='grayscale')\n",
    "\n",
    "\n",
    "datagenTest = ImageDataGenerator()\n",
    "test_generator = datagenTest.flow_from_dataframe(\n",
    "df_test,\n",
    "class_mode = None,\n",
    "directory = path_directory_test,\n",
    "color_mode='grayscale',\n",
    "target_size=(100,100),\n",
    "shuffle= True,\n",
    "batch_size = 32)\n",
    "\n",
    "training_steps = train_generator.n // train_generator.batch_size\n",
    "validation_steps = validation_generator.n // validation_generator.batch_size\n",
    "test_steps = test_generator.n // test_generator.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples,labels = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation='relu',input_shape=(100,100,1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(88, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=binary_crossentropy,metrics=['accuracy'],optimizer='Adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=training_steps,\n",
    "                    epochs=2,validation_data=validation_generator,\n",
    "                    validation_steps=validation_steps)\n",
    "\n",
    "model.save( r'C:\\Users\\Gebruiker\\Desktop\\model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSpectogram(sourcePath,targetPath):     #generate Mel-spectogram from wav \n",
    "    plt.box(0)\n",
    "    base, ext= os.path.splitext(file) #saving generated spectogram in target directory\n",
    "    samples, sampling_rate = librosa.load(sourcePath)\n",
    "    spectogram = librosa.stft(samples)\n",
    "    mel = librosa.feature.melspectrogram(y=samples,sr=sampling_rate,S=spectogram,n_fft=2048,hop_length=512,n_mels=128)\n",
    "    mel_dB = librosa.amplitude_to_db(np.abs(mel)) \n",
    "    librosa.display.specshow(mel_dB,cmap='gray')\n",
    "    plt.savefig(targetPath  + f\"\\\\{base}\" + \".png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in os.listdir('C:\\\\Users\\\\Gebruiker\\\\Desktop\\\\testSamples-Guitar\\\\'):\n",
    "    generateSpectogram('C:\\\\Users\\\\Gebruiker\\\\Desktop\\\\testSamples-Guitar\\\\'+ f\"\\\\{file}\",'C:\\\\Users\\\\Gebruiker\\\\Desktop\\\\testSamples-Guitar\\\\New folder')  #generating spectogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['A0','A#0','B0','C1','C#1','D1','D#1','E1','F1',\n",
    "         'F#1','G1','G#1','A1','A#1','B1','C2','C#2','D2','D#2','E2','F2',\n",
    "         'F#2','G2','G#2','A2','A#2','B2','C3','C#3','D3','D#3','E3','F3',\n",
    "         'F#3','G3','G#3','A3','A#3','B3','C4','C#4','D4','D#4','E4','F4',\n",
    "         'F#4','G4','G#4','A4','A#4','B4','C5','C#5','D5','D#5','E5','F5',\n",
    "         'F#5','G5','G#5','A5','A#5','B5','C6','C#6','D6','D#6','E6','F6',\n",
    "         'F#6','G6','G#6','A6','A#6','B6','C7','C#7','D7','D#7','E7','F7',\n",
    "         'F#7','G7','G#7','A7','A#7','B7','C8']\n",
    "\n",
    "noteDictionary = {}\n",
    "\n",
    "for index,note in enumerate(class_list):\n",
    "    noteDictionary[index] = note\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset\n",
    "model = tf.keras.models.load_model( r'C:\\Users\\Gebruiker\\Desktop\\model.h5')\n",
    "#predictions = model.predict_generator(test_generator,steps = test_steps)\n",
    "\n",
    "predictions = predictions.tolist()\n",
    "for i,prediction in enumerate(predictions):\n",
    "    print(i)\n",
    "    try:\n",
    "        indexOutput = prediction.index(1)\n",
    "    except:\n",
    "        print('Could not generate output for this image')\n",
    "    else:\n",
    "        print(noteDictionary.get(indexOutput))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A0',\n",
       " 'A#0',\n",
       " 'B0',\n",
       " 'C1',\n",
       " 'C#1',\n",
       " 'D1',\n",
       " 'D#1',\n",
       " 'E1',\n",
       " 'F1',\n",
       " 'F#1',\n",
       " 'G1',\n",
       " 'G#1',\n",
       " 'A1',\n",
       " 'A#1',\n",
       " 'B1',\n",
       " 'C2',\n",
       " 'C#2',\n",
       " 'D2',\n",
       " 'D#2',\n",
       " 'E2',\n",
       " 'F2',\n",
       " 'F#2',\n",
       " 'G2',\n",
       " 'G#2',\n",
       " 'A2',\n",
       " 'A#2',\n",
       " 'B2',\n",
       " 'C3',\n",
       " 'C#3',\n",
       " 'D3',\n",
       " 'D#3',\n",
       " 'E3',\n",
       " 'F3',\n",
       " 'F#3',\n",
       " 'G3',\n",
       " 'G#3',\n",
       " 'A3',\n",
       " 'A#3',\n",
       " 'B3',\n",
       " 'C4',\n",
       " 'C#4',\n",
       " 'D4',\n",
       " 'D#4',\n",
       " 'E4',\n",
       " 'F4',\n",
       " 'F#4',\n",
       " 'G4',\n",
       " 'G#4',\n",
       " 'A4',\n",
       " 'A#4',\n",
       " 'B4',\n",
       " 'C5',\n",
       " 'C#5',\n",
       " 'D5',\n",
       " 'D#5',\n",
       " 'E5',\n",
       " 'F5',\n",
       " 'F#5',\n",
       " 'G5',\n",
       " 'G#5',\n",
       " 'A5',\n",
       " 'A#5',\n",
       " 'B5',\n",
       " 'C6',\n",
       " 'C#6',\n",
       " 'D6',\n",
       " 'D#6',\n",
       " 'E6',\n",
       " 'F6',\n",
       " 'F#6',\n",
       " 'G6',\n",
       " 'G#6',\n",
       " 'A6',\n",
       " 'A#6',\n",
       " 'B6',\n",
       " 'C7',\n",
       " 'C#7',\n",
       " 'D7',\n",
       " 'D#7',\n",
       " 'E7',\n",
       " 'F7',\n",
       " 'F#7',\n",
       " 'G7',\n",
       " 'G#7',\n",
       " 'A7',\n",
       " 'A#7',\n",
       " 'B7',\n",
       " 'C8']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
